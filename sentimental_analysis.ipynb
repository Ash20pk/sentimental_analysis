{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcgBmJtPv_7K"
      },
      "source": [
        "# 1. Set up environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL85sjrzv_7K"
      },
      "source": [
        "The boring part!\n",
        "\n",
        "Installs all required dependencies and spins up a local devnet that will run Nada programs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4PXBlE2v_7K",
        "outputId": "3427388e-6089-4d0c-fe10-db3bde3ca5a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install nada-ai~=0.3.0 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rmTAavFov_7L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import sys\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jtEZDic_ASKl"
      },
      "outputs": [],
      "source": [
        "# Configure telemetry settings\n",
        "enable_telemetry = True  #@param {type:\"boolean\"}\n",
        "my_identifier = \"test\"  #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcsYIHINv_7L",
        "outputId": "b369d096-ba55-41b6-e53d-4ec4de925a8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  7810  100  7810    0     0   6008      0  0:00:01  0:00:01 --:--:--  6012\n",
            "\n",
            "nilup has been installed into /Users/ash/.nilup/bin.\n",
            "\n",
            "$PATH is already up-to-date. You may begin using nilup now!\n",
            "\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'sys' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurl https://nilup.nilogy.xyz/install.sh | bash\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Update Path if ran in colab\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle.colab\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43msys\u001b[49m\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[1;32m      6\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:/root/.nilup/bin\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:/root/.nilup/sdks/latest/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
          ]
        }
      ],
      "source": [
        "# Install the nilup tool and then use that to install the Nillion SDK\n",
        "!curl https://nilup.nilogy.xyz/install.sh | bash\n",
        "\n",
        "# # Update Path if ran in colab\n",
        "# if \"google.colab\" in sys.modules:\n",
        "#     os.environ[\"PATH\"] += \":/root/.nilup/bin\"\n",
        "#     os.environ[\"PATH\"] += \":/root/.nilup/sdks/latest/\"\n",
        "\n",
        "# Set telemetry if opted in\n",
        "if enable_telemetry:\n",
        "    identifier = f\"nada-ai-spam-detection-{str(uuid.uuid4())}-{my_identifier}\"\n",
        "    !echo 'yes' | nilup instrumentation enable --wallet {identifier}\n",
        "\n",
        "# Install the lastest SDK and initialise it\n",
        "!nilup init\n",
        "!nilup install latest\n",
        "!nilup use latest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3CluM_vv_7L",
        "outputId": "c61d0d8e-b970-4614-9a82-ef27f106c8ad"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Spin up local Nillion devnet\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39msystem\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnohup nillion-devnet &\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m20\u001b[39m)  \u001b[38;5;66;03m# Wait for devnet\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "# Spin up local Nillion devnet\n",
        "get_ipython().system = os.system\n",
        "!nohup nillion-devnet &\n",
        "\n",
        "time.sleep(20)  # Wait for devnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QluoKNsev_7L"
      },
      "source": [
        "# 2. Build Nada program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT37dfFhv_7L",
        "outputId": "3951c6ae-69fd-4a9a-b0ea-ece1590b63c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building program: \u001b[1m\u001b[32msentimental_analysis\u001b[39m\u001b[0m\n",
            "\u001b[1;32mBuild complete!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!nada build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkWJ_oikv_7M",
        "outputId": "c950177c-01f5-4143-ba28-e0468fb1749c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentimental_analysis.nada.bin\n"
          ]
        }
      ],
      "source": [
        "# You will see that the program was compiled in a .nada.bin file\n",
        "!ls target | grep sentimental_analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZUGIJWyv_7M"
      },
      "source": [
        "# 4. Provide model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gpe-MQ57xVh"
      },
      "source": [
        "Let's step into the shoes of the model provider.\n",
        "\n",
        "We will train a spam detection model and upload the weights as secrets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-X12FEUL_H4",
        "outputId": "eed0411a-fe5a-4bdd-bf6b-e99470ecd6ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
        "\n",
        "import zipfile\n",
        "\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from io import BytesIO\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from config import DIM\n",
        "\n",
        "home = os.getenv(\"HOME\")\n",
        "load_dotenv(f\"{home}/sentimental_analysis/nillion-testnet.env\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrfAO_RTMG5l"
      },
      "outputs": [],
      "source": [
        "# Load the movie review Dataset\n",
        "df = pd.read_csv('dataset/movie_reviews.csv', header=0, sep=\",\", names=[\"review\", \"sentiment\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Hb6I05y2MKDz",
        "outputId": "84c14d63-08e6-467c-dbb4-75ebac904798"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Wf2WMB95MLPY"
      },
      "outputs": [],
      "source": [
        "# Split data into features and labels\n",
        "X = df[\"review\"]\n",
        "y = df[\"sentiment\"].map({\"positive\": 1, \"negative\": 0}) # Convert labels to binary (1 for positive, 0 for negative)\n",
        "\n",
        "\n",
        "# 3. Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYnJ4jcxMLsI",
        "outputId": "9fa1532c-f133-46d0-d58c-12403a37876e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['model/vectorizer.joblib']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transform text to set of numerical features\n",
        "vectorizer = TfidfVectorizer(max_features=DIM)  # Limiting to fixed set of features\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Save the vectorizer to a file\n",
        "joblib.dump(vectorizer, \"model/vectorizer.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "_wvq3gAvMLvn",
        "outputId": "53ff3699-244a-42a3-c63c-b60a75f42595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learned model coeffs are: [[ 0.21636137 -0.16730774  1.63125533 ... -0.87058316 -1.24181246\n",
            "  -0.0494308 ]]\n",
            "Learned model intercept is: [0.01389142]\n"
          ]
        }
      ],
      "source": [
        "# Train the logistic regression model\n",
        "model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "print(\"Learned model coeffs are:\", model.coef_)\n",
        "print(\"Learned model intercept is:\", model.intercept_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu9BidsnMN92",
        "outputId": "7b49e423-51b8-4f73-9662-ec4da5665ac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.90\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.90      0.88      0.89      4961\n",
            "    Positive       0.89      0.91      0.90      5039\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.89      0.89     10000\n",
            "weighted avg       0.90      0.90      0.89     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 6. Evaluate the model\n",
        "y_pred = model.predict(X_test_vectorized)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGaedw7NMRHZ",
        "outputId": "20991856-8241-400a-9fe1-3da244ed1dec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['model/classifier.joblib']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the classifier to a file\n",
        "joblib.dump(model, \"model/classifier.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s24ZNZ3MRKQ",
        "outputId": "31ffef53-c17c-4d0d-8b41-efe441dc8493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Importing plotly failed. Interactive plots will not work.\n",
            "Storing program...\n",
            "Getting quote for operation...\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/ash/sentimental_analysis/01_provide_model.py\", line 120, in <module>\n",
            "    asyncio.run(main(ARGS.model_path, ARGS.out_path))\n",
            "  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/runners.py\", line 194, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 687, in run_until_complete\n",
            "    return future.result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/Users/ash/sentimental_analysis/01_provide_model.py\", line 73, in main\n",
            "    program_id = await store_program(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/ash/sentimental_analysis/common/utils.py\", line 82, in store_program\n",
            "    quote_store_program = await get_quote(\n",
            "                          ^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/ash/.local/lib/python3.12/site-packages/nillion_python_helpers/payments.py\", line 62, in get_quote\n",
            "    quote = await client.request_price_quote(cluster_id, operation)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: requesting price quote: price quote query failed: price quote query failed: processing target program failed: program audit failed: error auditing program: invalid program: failure in policy max_memory: maximum memory limit exceeded for program, program memory is 20001, maximum: 10000\n"
          ]
        }
      ],
      "source": [
        "!python 01_provide_model.py \\\n",
        "    --model-path model/classifier.joblib \\\n",
        "    --out-path target/identifiers.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHICew6s65tF"
      },
      "source": [
        "# 5. Provide input and run inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOGsrHlQ79HM"
      },
      "source": [
        "Now that the model has been provided, we can step into the shoes of the model user.\n",
        "\n",
        "We will provide an input to the program and run the model on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "pL9VnIGIZ8Lf"
      },
      "outputs": [],
      "source": [
        "vectorizer: TfidfVectorizer = joblib.load(\"model/vectorizer.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "bfILPayrZ81f"
      },
      "outputs": [],
      "source": [
        "# Let's find out whether it's a billion dollar opportunity or pyramid scheme\n",
        "INPUT_DATA = \"this movie is a awesome, I just loved the actors and the suppoting cast I feel more movies like this should be made\"\n",
        "\n",
        "[features] = vectorizer.transform([INPUT_DATA]).toarray().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "bf00kkqyZ83n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<module 'numpy' from '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/__init__.py'>\n"
          ]
        }
      ],
      "source": [
        "features = np.array(features).astype(float)\n",
        "print(np);\n",
        "np.save(\"model/features.npy\", features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgmLvYOb656M",
        "outputId": "02141e64-5714-4d66-ede6-2b44ac8179a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Storing input data...\n",
            "Getting quote for operation...\n",
            "Quote cost is 48002 unil\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/Users/ash/sentimental_analysis/02_run_inference.py\", line 140, in <module>\n",
            "    asyncio.run(main(ARGS.features_path, ARGS.in_path))\n",
            "  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/runners.py\", line 194, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 687, in run_until_complete\n",
            "    return future.result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/Users/ash/sentimental_analysis/02_run_inference.py\", line 87, in main\n",
            "    features_store_id = await store_secret_array(\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/ash/sentimental_analysis/common/utils.py\", line 134, in store_secret_array\n",
            "    store_id = await store_secrets(\n",
            "               ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/ash/sentimental_analysis/common/utils.py\", line 224, in store_secrets\n",
            "    receipt_store = await get_quote_and_pay(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/ash/.local/lib/python3.12/site-packages/nillion_python_helpers/payments.py\", line 35, in get_quote_and_pay\n",
            "    submitted_tx = prepare_and_broadcast_basic_transaction(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/ash/.local/lib/python3.12/site-packages/cosmpy/aerial/client/utils.py\", line 78, in prepare_and_broadcast_basic_transaction\n",
            "    return client.broadcast_tx(tx)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/ash/.local/lib/python3.12/site-packages/cosmpy/aerial/client/__init__.py\", line 764, in broadcast_tx\n",
            "    initial_tx_response.ensure_successful()\n",
            "  File \"/Users/ash/.local/lib/python3.12/site-packages/cosmpy/aerial/tx_helpers.py\", line 97, in ensure_successful\n",
            "    raise BroadcastError(self.hash, self.raw_log)\n",
            "cosmpy.aerial.exceptions.BroadcastError: account sequence mismatch, expected 61, got 60: incorrect account sequence\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!python 02_run_inference.py \\\n",
        "    --features-path model/features.npy \\\n",
        "    --in-path target/identifiers.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB8mjasbaGYs",
        "outputId": "8ff227b8-1eaa-470d-8739-4decf108d4b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logit in plain text: -0.9943009892551997\n",
            "Probability of spam in plain text: 27.006339%\n"
          ]
        }
      ],
      "source": [
        "# Let's sense-check these results versus what we would have gotten in plain-text\n",
        "vectorizer: TfidfVectorizer = joblib.load(\"model/vectorizer.joblib\")\n",
        "classifier: LogisticRegression = joblib.load(\"model/classifier.joblib\")\n",
        "features = vectorizer.transform([INPUT_DATA]).toarray().tolist()\n",
        "\n",
        "[logit_plain_text] = classifier.decision_function(features)\n",
        "probabilities = 1 / (1 + np.exp(-logit_plain_text))\n",
        "sentiment = \"positive\" if probabilities > 0.5 else \"negative\"\n",
        "print(\"Logit in plain text: {}\".format(logit_plain_text))\n",
        "\n",
        "output_probability_plain_text = classifier.predict_proba(features)[0][1]\n",
        "print(\n",
        "    \"Probability of spam in plain text: {:.6f}%\".format(\n",
        "        output_probability_plain_text * 100\n",
        "    )\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
